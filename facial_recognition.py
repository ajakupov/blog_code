import cv2
import face_recognition
import numpy as np


WINDOW_NAME = "FACIAL RECOGNITION"
FONT = cv2.FONT_HERSHEY_DUPLEX
RED = (0, 0, 255)
GREEN = (0, 255, 0)
WHITE = (255, 255, 255)
REDUCE_RATE = 0.25


def adapt_image(frame):
    """Adapt an OpenCV frame for facial recognition

    Args:
        frame (np.ndarray): OpenCV image

    Returns:
        np.ndarray: A continous array compatible with face_recogntion
    """
    small_frame = cv2.resize(frame, (0, 0), fx=REDUCE_RATE, fy=REDUCE_RATE)
    rgb_small_frame = np.ascontiguousarray(small_frame[:, :, ::-1])
    return rgb_small_frame


def adapt_coordinates(face_location):
    """Adapt the face_recognition output after resizing

    Args:
        face_location (tuple): top, right, bottom, left

    Returns:
        tuple: top, right, bottom, left
    """
    top, right, bottom, left = face_location

    multiplier = int(1/REDUCE_RATE)

    top *= multiplier
    right *= multiplier
    bottom *= multiplier
    left *= multiplier

    return (top, right, bottom, left)


def get_face_names(face_encodings, known_face_encodings, known_face_names):
    """Get the corresponding face names for matches

    Args:
        face_encodings (list): an array of face encodings generated by face_recognition
        known_face_encodings (list): an array of face encodings generated by face_recognition out of pictures
        known_face_names (list): an of array of string, corresponding to the picture names

    Returns:
        list: all the names for each face encoding
    """
    face_names = []

    for face_encoding in face_encodings:
        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)

        name = "Unknown"

        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)

        best_match_index = np.argmin(face_distances)

        if matches[best_match_index]:
            name = known_face_names[best_match_index]
        
        face_names.append(name)
    
    return face_names



video_capture = cv2.VideoCapture("beans.mp4")
jim_image = face_recognition.load_image_file("jim.jpeg")
jim_face_encoding = face_recognition.face_encodings(jim_image)[0]
kaley_image = face_recognition.load_image_file("kaley.jpeg")
kaley_face_encoding = face_recognition.face_encodings(kaley_image)[0]

known_face_encodings = [
    jim_face_encoding,
    kaley_face_encoding
]
known_face_names = [
    "Jim Parons",
    "Kaley Cuoco"
]

counter = 0

while True:
    ret, frame = video_capture.read()

    adapted_frame = adapt_image(frame)
    face_locations = face_recognition.face_locations(adapted_frame)
    face_encodings = face_recognition.face_encodings(adapted_frame, face_locations)
    face_names = get_face_names(face_encodings, known_face_encodings, known_face_names)

    for face_location, name in zip(face_locations, face_names):

        top, right, bottom, left = adapt_coordinates(face_location)
        color = RED

        if name != "Unknown":
            color = GREEN
        
        cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
        cv2.putText(frame, name, (left, bottom), FONT, 1.0, WHITE, 1)


    cv2.imshow(WINDOW_NAME, frame)

    counter += 1

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

video_capture.release()
cv2.destroyAllWindows()